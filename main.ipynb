{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset.dataset import AVADataset\n",
    "\n",
    "from model.model import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.getenv(\"AVA_IMAGE_PATH\")\n",
    "TRAIN_CSV = os.getenv(\"AVA_TRAIN_CSV\")\n",
    "TEST_CSV  = os.getenv(\"AVA_TEST_CSV\")\n",
    "VAL_CSV   = os.getenv(\"AVA_VAL_CSV\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CONV_LEARNING_RATE = 5e-4\n",
    "DENSE_LEARNING_RATE = 5e-3\n",
    "\n",
    "DECAY = False\n",
    "\n",
    "EPOCHS = 100\n",
    "EARLY_STOPPING = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = AVADataset(TRAIN_CSV, IMAGE_PATH, transform=train_transform)\n",
    "valset   = AVADataset(VAL_CSV, IMAGE_PATH, transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count())\n",
    "val_loader   = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epoch, train_losses, avg_loss):\n",
    "    # Train\n",
    "    batch_losses = []\n",
    "    pbar = tqdm(train_loader)\n",
    "    for i, data in enumerate(pbar):\n",
    "        images = data['image'].to(device)\n",
    "        labels = data['annotations'].to(device).float()\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.view(-1, 10, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = emd_loss(labels, outputs)\n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('batch train loss', loss.data[0], i + epoch * (len(trainset) // BATCH_SIZE + 1))\n",
    "        \n",
    "        # tqdm description\n",
    "        pbar.set_description('Epoch: [{0}][{1}/{2}]\\t' 'Batch Loss {loss:.4f}\\t'.format(epoch, i, len(trainset) // BATCH_SIZE + 1, loss=loss.data[0]))\n",
    "    \n",
    "    avg_loss = np.sum(batch_losses) / (len(trainset) // BATCH_SIZE + 1)\n",
    "    train_losses.append(avg_loss)\n",
    "    print('Epoch: [{0}]\\t' 'Mean Training EMD Loss {loss:.4f}\\t'.format(epoch + 1, loss=avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_losses, avg_val_loss, avg_loss, epoch):\n",
    "    # Validation\n",
    "    batch_val_losses = []\n",
    "    pbar = tqdm(val_loader)\n",
    "    for data in pbar:\n",
    "        images = data['image'].to(device)\n",
    "        labels = data['annotations'].to(device).float()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        outputs = outputs.view(-1, 10, 1)\n",
    "        val_loss = emd_loss(labels, outputs)\n",
    "        batch_val_losses.append(val_loss.item())\n",
    "        \n",
    "        # tqdm description\n",
    "        pbar.set_description('Epoch: [{0}] Validation Loss {loss:.4f}\\t'.format(epoch, loss=val_loss.data[0]))\n",
    "        \n",
    "    avg_val_loss = np.sum(batch_val_losses) / (len(valset) // BATCH_SIZE + 1)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print('Epoch: [{0}]\\t' 'Mean Validation EMD Loss {loss:.4f}\\t'.format(epoch + 1, loss=avg_val_loss))\n",
    "    writer.add_scalars('epoch loss', {'train': avg_loss, 'val': avg_val_loss}, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.vgg16(weights = models.VGG16_Weights.DEFAULT)\n",
    "model = NIMA(base_model).to(device)\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.features.parameters(), 'lr': CONV_LEARNING_RATE},\n",
    "    {'params': model.classifier.parameters(), 'lr': DENSE_LEARNING_RATE}],\n",
    "    momentum=0.9)\n",
    "\n",
    "param_num = 0\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        param_num += param.numel()\n",
    "print('Total trainable parameters: %d' % param_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "init_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    \n",
    "    # train\n",
    "    train_model(model, optimizer, epoch, train_losses, avg_loss)\n",
    "    \n",
    "    # validate\n",
    "    validation(model, val_losses, avg_val_loss, avg_loss, epoch)\n",
    "    \n",
    "    if avg_val_loss < init_val_loss:\n",
    "        init_val_loss = avg_val_loss\n",
    "        \n",
    "        # save model\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.makedirs('checkpoints')\n",
    "        torch.save(model.state_dict(), os.path.join('checkpoints', f'epoch_{epoch + 1}_val_loss_{avg_val_loss}.pth'))\n",
    "        print('Model saved')\n",
    "        count = 0\n",
    "    elif avg_val_loss >= init_val_loss:\n",
    "        count += 1\n",
    "        if count == EARLY_STOPPING:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
